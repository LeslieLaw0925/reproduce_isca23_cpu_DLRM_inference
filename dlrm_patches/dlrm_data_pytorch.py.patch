--- ../training/bfloat16/dlrm_data_pytorch.py	2022-09-12 12:38:48.503994937 +0000
+++ dlrm_data_pytorch.py	2022-09-25 19:36:55.820259467 +0000
@@ -49,7 +49,6 @@
 from torch.utils.data import Dataset, RandomSampler
 
 import data_loader_terabyte
-import mlperf_logger
 import extend_distributed as ext_dist
 
 
@@ -627,6 +626,15 @@
                 self.trace_file,
                 self.enable_padding
             )
+        elif self.data_generation == "constant" or self.data_generation == "alibaba":
+            fn = generate_constant_input_batch if self.data_generation == "constant" else generate_alibaba_input_batch
+            (X, lS_o, lS_i) = fn(
+                self.m_den,
+                self.ln_emb,
+                n,
+                self.num_indices_per_lookup,
+                self.num_indices_per_lookup_fixed,
+            )
         else:
             sys.exit(
                 "ERROR: --data-generation=" + self.data_generation + " is not supported"
@@ -730,6 +738,15 @@
                 trace_file,
                 enable_padding
             )
+        elif data_generation == "constant" or data_generation == "alibaba":
+            fn = generate_constant_input_batch if data_generation == "constant" else generate_alibaba_input_batch
+            (Xt, lS_emb_offsets, lS_emb_indices) = fn(
+                m_den,
+                ln_emb,
+                n,
+                num_indices_per_lookup,
+                num_indices_per_lookup_fixed
+            )
         else:
             sys.exit(
                 "ERROR: --data-generation=" + data_generation + " is not supported"
@@ -873,6 +890,99 @@
             # update offset for next iteration
             offset += sparse_group_size
         lS_emb_offsets.append(torch.tensor(lS_batch_offsets))
+        lS_emb_indices.append(torch.tensor(lS_batch_indices))
+
+    return (Xt, lS_emb_offsets, lS_emb_indices)
+
+
+# constant distribution (input data)
+def generate_constant_input_batch(
+    m_den,
+    ln_emb,
+    n,
+    num_indices_per_lookup,
+    num_indices_per_lookup_fixed,
+):
+    # dense feature
+    Xt = torch.ones(n, m_den, dtype=torch.float32)
+
+    # sparse feature (sparse indices)
+    lS_emb_offsets = []
+    lS_emb_indices = []
+    # for each embedding generate a list of n lookups,
+    # where each lookup is composed of multiple sparse indices
+    for size in ln_emb:
+        lS_batch_offsets = []
+        lS_batch_indices = []
+        offset = 0
+        for _ in range(n):
+            # num of sparse indices to be used per embedding (between
+            if num_indices_per_lookup_fixed:
+                sparse_group_size = np.int64(num_indices_per_lookup)
+            else:
+                assert False
+            # store lengths and indices
+            lS_batch_offsets += [offset]
+            lS_batch_indices += [1] * sparse_group_size
+            # update offset for next iteration
+            offset += sparse_group_size
+        lS_emb_offsets.append(torch.tensor(lS_batch_offsets))
+        lS_emb_indices.append(torch.tensor(lS_batch_indices))
+
+    return (Xt, lS_emb_offsets, lS_emb_indices)
+
+
+# alibaba (input data)
+def generate_alibaba_input_batch(
+    m_den,
+    ln_emb,
+    n,
+    num_indices_per_lookup,
+    num_indices_per_lookup_fixed,
+):
+    # alibaba dataset
+    idx_list = []
+    with open('/home/cc/dataset/items_in_buy.txt') as f:
+        idx_list = [int(x) % 500000 for x in f]
+    print('Alibaba dataset len:', len(idx_list))
+    start_idx = 0
+
+    # dense feature
+    Xt = torch.tensor(ra.rand(n, m_den).astype(np.float32))
+
+    # sparse feature (sparse indices)
+    lS_emb_offsets = []
+    lS_emb_indices = []
+    # for each embedding generate a list of n lookups,
+    # where each lookup is composed of multiple sparse indices
+    for size in ln_emb:
+        lS_batch_offsets = []
+        lS_batch_indices = []
+        offset = 0
+        for _ in range(n):
+            # num of sparse indices to be used per embedding (between
+            if num_indices_per_lookup_fixed:
+                sparse_group_size = np.int64(num_indices_per_lookup)
+            else:
+                # random between [1,num_indices_per_lookup])
+                r = ra.random(1)
+                sparse_group_size = np.int64(
+                    np.round(max([1.0], r * min(size, num_indices_per_lookup)))
+                )
+            # sparse indices to be used per embedding
+            r = ra.random(sparse_group_size)
+            sparse_group = np.unique(np.round(r * (size - 1)).astype(np.int64))
+            # reset sparse_group_size in case some index duplicates were removed
+            sparse_group_size = np.int64(sparse_group.size)
+            # store lengths and indices
+            lS_batch_offsets += [offset]
+            lS_batch_indices += idx_list[start_idx:start_idx + sparse_group_size]
+            start_idx += sparse_group_size
+            if start_idx > len(idx_list) - sparse_group_size:
+                start_idx = 0
+            # update offset for next iteration
+            offset += sparse_group_size
+        lS_emb_offsets.append(torch.tensor(lS_batch_offsets))
         lS_emb_indices.append(torch.tensor(lS_batch_indices))
 
     return (Xt, lS_emb_offsets, lS_emb_indices)
